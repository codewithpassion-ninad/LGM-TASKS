{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LETS GROW MORE INTERNSHIP - AUGUST 2023**\\\n",
    "**TASK - PREDICT THE NEXT CHARACTER OF WORD OR WORD OF THE SENTENCE**\\\n",
    "**NINAD NILESH SUGANDHI**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "import warnings as wg\n",
    "wg.filterwarnings(\"ignore\")\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Activation, Dropout, RepeatVector, TimeDistributed, Embedding\n",
    "from tensorflow.keras.optimizers import  RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import heapq\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 581888\n"
     ]
    }
   ],
   "source": [
    "data= open(\"D:\\\\NINAD SUGANDHI\\\\GOOGLE COLAB\\\\LGM PROJECTS\\\\Next Word Prediction Dataset.txt\", encoding=\"utf8\").read().lower()\n",
    "print('corpus length:', len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique chars: 73\n"
     ]
    }
   ],
   "source": [
    "character = sorted(list(set(data)))\n",
    "char_indices = dict((c, i) for i, c in enumerate(character))\n",
    "indices_char = dict((i, c) for i, c in enumerate(character))\n",
    "\n",
    "print(f'unique chars: {len(character)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num training examples: 193950\n"
     ]
    }
   ],
   "source": [
    "seq_len = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(data) - seq_len, step):\n",
    "    sentences.append(data[i: i + seq_len ])\n",
    "    next_chars.append(data[i + seq_len])\n",
    "print(f'num training examples: {len(sentences)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.zeros((len(sentences), seq_len, len(character)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(character)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "sentences[124]\n",
    "next_chars[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193950, 40, 73)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193950, 73)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Developing model and training it using the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28917"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "total_words = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_19 (LSTM)              (None, 500)               1148000   \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 73)                36573     \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 73)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1184573 (4.52 MB)\n",
      "Trainable params: 1184573 (4.52 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creating the model\n",
    "model = Sequential()\n",
    "model.add(LSTM(500, input_shape=(seq_len, len(character))))\n",
    "model.add(Dense(len(character)))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "6061/6061 [==============================] - 2007s 331ms/step - loss: 2.1130 - accuracy: 0.3863\n",
      "Epoch 2/5\n",
      "6061/6061 [==============================] - 1965s 324ms/step - loss: 1.6558 - accuracy: 0.5030\n",
      "Epoch 3/5\n",
      "6061/6061 [==============================] - 2065s 341ms/step - loss: 1.4592 - accuracy: 0.5562\n",
      "Epoch 4/5\n",
      "6061/6061 [==============================] - 2149s 355ms/step - loss: 1.3224 - accuracy: 0.5922\n",
      "Epoch 5/5\n",
      "6061/6061 [==============================] - 2298s 379ms/step - loss: 1.2069 - accuracy: 0.6228\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X, y, epochs = 5, verbose=1)\n",
    "model.save('nextword.h5')\n",
    "pickle.dump(history, open(\"history.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining all the functions needed for the predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(text):\n",
    "    x = np.zeros((1, seq_len, len(character)))\n",
    "    for t, char in enumerate(text):\n",
    "        x[0, t, char_indices[char]] = 1.\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "#functions to get next probable characters\n",
    "def sample(preds, top_n=3):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds)\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "\n",
    "    return heapq.nlargest(top_n, range(len(preds)), preds.take)\n",
    "\n",
    "def predict_completion(text, max_length=400):\n",
    "    original_text = text\n",
    "    generated = text\n",
    "    completion = ''\n",
    "    \n",
    "    # Generate text until reaching the maximum length or a space character\n",
    "    while len(original_text + completion) < max_length:\n",
    "        x = prepare_input(text)\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        next_index = sample(preds, top_n=1)[0]\n",
    "        next_char = indices_char[next_index]\n",
    "        text = text[1:] + next_char\n",
    "        completion += next_char\n",
    "        \n",
    "        # If a space is encountered, return the completion\n",
    "        if next_char == ' ':\n",
    "            return completion\n",
    "    \n",
    "    return completion\n",
    "    \n",
    "def predict_completions(text, n=3):\n",
    "    x = prepare_input(text)\n",
    "    preds = model.predict(x, verbose=0)[0]\n",
    "    next_indices = sample(preds, n)\n",
    "    return [indices_char[idx] + predict_completion(text[1:] + indices_char[idx]) for idx in next_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"With great power comes great responsibility.\", \"India's diversity weaves a tapestry of innovation and influence across the globe.\", \n",
    "\"In a world of magic and wonder, Harry Potter taught us the strength of friendship and courage.\", \"Sachin's bat carved not just records, but a legacy of cricketing devotion.\",\n",
    "\"Artificial Intelligence is the silent revolution reshaping our present and defining our future.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with great power comes great responsibil\n",
      "['ity ', 'less ', 'ate ', ' the ', '\\nthe ']\n",
      "\n",
      "india's diversity weaves a tapestry of i\n",
      "['nterest ', 't. ', 'mpression. ', ' trust ', '\\nto ']\n",
      "\n",
      "in a world of magic and wonder, harry po\n",
      "['ints ', 'liced ', 'ssible ', 'or ', 'wn ']\n",
      "\n",
      "sachin's bat carved not just records, bu\n",
      "['t ', 'ring ', 's ', 'c ', 'liness ']\n",
      "\n",
      "artificial intelligence is the silent re\n",
      "['adon\\nwhich ', 'spertaining ', 'd ', 'periesce ', 'ceived ']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in labels:\n",
    "    seq = i[:40].lower()\n",
    "    print(seq)\n",
    "    print(predict_completions(seq, 5))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Printing the loss and accuracy of the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6061/6061 [==============================] - 990s 163ms/step - loss: 1.0360 - accuracy: 0.6764\n",
      "Test Loss 1.0359888076782227\n",
      "Test Accuracy 0.6763702034950256\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X,y)\n",
    "print(\"Test Loss\", loss)\n",
    "print(\"Test Accuracy\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\\\n",
    "*In this task, I have built a text generation model using LSTM that can predict the possible next word in a sequence based on the provided text dataset. The model was trained using TensorFlow/Keras and involved tokenizing the text, creating input sequences, and training an LSTM-based neural network. I have also used the trained model, demonstrating its ability to produce coherent sequences of words.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
